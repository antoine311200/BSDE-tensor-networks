{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsde_solver.core.tensor.tensor_train import TensorTrain, left_unfold, right_unfold\n",
    "from bsde_solver.core.tensor.tensor_core import TensorCore\n",
    "from bsde_solver.core.tensor.tensor_network import TensorNetwork\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TensorTrain(shape=[4, 4, 4, 4], ranks=[1, 3, 3, 3, 1])\n",
    "tt.randomize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of several functions and algorithms with tensor train decomposition using the following random tensor train (matrix product state):\n",
    "\n",
    "<center><img src=\"./images/test_tt.png\" style=\"width: 40%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left and Right unfoldings\n",
    "\n",
    "Left unfolding:\n",
    "<center><img src=\"./images/left_unfold.png\" style=\"width: 40%\"/></center>\n",
    "\n",
    "Right unfolding:\n",
    "<center><img src=\"./images/right_unfold.png\" style=\"width: 40%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = right_unfold(tt[1])\n",
    "L = left_unfold(tt[1])\n",
    "\n",
    "print(R)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left and Right orthogonalizations\n",
    "\n",
    "\n",
    "Left orthogonalization:\n",
    "<center><img src=\"./images/tt_left_ortho.png\" style=\"width: 40%\"/></center>\n",
    "\n",
    "Right orthogonalization:\n",
    "<center><img src=\"./images/tt_right_ortho.png\" style=\"width: 40%\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1 = tt.copy()\n",
    "tt2 = tt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt[0].view(np.ndarray), tt1[0].view(np.ndarray), tt2[0].view(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1.orthonormalize(mode=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/tt_left_ortho_id.png\" style=\"width: 30%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = left_unfold(tt1[1]).view(np.ndarray)\n",
    "L.T @ L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2.orthonormalize(mode=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/tt_right_ortho_id.png\" style=\"width: 30%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = right_unfold(tt2[3]).view(np.ndarray)\n",
    "R @ R.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left & Right part of the tensor train\n",
    "\n",
    "Left part :\n",
    "<center><img src=\"./images/left_contract.png\" style=\"width: 50%\"/></center>\n",
    "Right part :\n",
    "<center><img src=\"./images/right_contract.png\" style=\"width: 50%\"/></center>\n",
    "\n",
    "Then, we can write the tensor train as:\n",
    "\n",
    "<center><img src=\"./images/left_right_repr.png\" style=\"width: 80%\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares (ALS) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_einsum import contract\n",
    "\n",
    "def retraction_operator(tt, i):\n",
    "    operator = tt.extract([f'core_{j}' for j in range(tt.order) if j != i])\n",
    "    return operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt3 = tt.copy()\n",
    "tt3.orthonormalize(mode=\"right\")\n",
    "\n",
    "print(tt3)\n",
    "\n",
    "P1 = retraction_operator(tt3, 0)\n",
    "print(\"\\nRectraction operator (1st):\")\n",
    "print(P1)\n",
    "print(P1.contract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt3.orthonormalize(mode=\"left\")\n",
    "tt3.orthonormalize(mode=\"right\", start=1)\n",
    "\n",
    "P2 = retraction_operator(tt3, 1)\n",
    "print(\"\\nRectraction operator (2nd):\")\n",
    "print(P2)\n",
    "print(P2.contract())\n",
    "\n",
    "P2_mat = P2.contract().unfold(('r_1', 'r_2'), -1).view(np.ndarray)\n",
    "(P2_mat @ P2_mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt3.orthonormalize(mode=\"left\")\n",
    "tt3.orthonormalize(mode=\"right\", start=2)\n",
    "\n",
    "P3 = retraction_operator(tt3, 2)\n",
    "print(P3.contract())\n",
    "P3_mat = P3.contract().unfold(('r_2', 'r_3'), -1).view(np.ndarray)\n",
    "(P3_mat @ P3_mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = tt.copy()\n",
    "ttt.orthonormalize(mode=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt4 = tt.copy()\n",
    "tt5 = tt4.rename(\"m_*\", \"n_*\", inplace=False)\n",
    "tt4, tt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Micro-optimization\n",
    "\n",
    "At each step of the ALS algorithm, we need to compute the following expression:\n",
    "\n",
    "$$P_i^T A P_i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS(A, b, n_iter=10, ranks=None):\n",
    "    shape = [10, 10, 10]\n",
    "    ranks = [1, 3, 3, 1]\n",
    "    tt = TensorTrain(shape, ranks)\n",
    "    tt.randomize()\n",
    "    tt.orthonormalize(mode=\"right\", start=1)\n",
    "\n",
    "    print(tt)\n",
    "\n",
    "    def get_idx(j):\n",
    "        if j == 0: indices = (b[j].indices[0], *tt[j].indices[1:])\n",
    "        elif j == tt.order-1: indices = (*tt[j].indices[:-1], b[j].indices[2])\n",
    "        else: indices = tt[j].indices\n",
    "        return indices\n",
    "\n",
    "    def get_idx2(j):\n",
    "        if j == 0: indices = (f'r_{tt.order}', f'm_{j+1}', f'r_{j+1}', f't_{tt.order}', f'n_{j+1}', f't_{j+1}', )\n",
    "        #(f't_{tt.order-1}', *tt[j].indices[1:], )\n",
    "        elif j == tt.order-1: indices = (f'r_{j}', f'm_{j+1}', f'r_0', f't_{j}', f'n_{j+1}', f't_{0}', )\n",
    "        else: indices = (*tt[j].indices, f't_{j}', f'n_{j+1}', f't_{j+1}', )\n",
    "        return indices\n",
    "\n",
    "    def micro_optimization(tt, j):\n",
    "        P = retraction_operator(tt, j)\n",
    "        P.name = 'P'\n",
    "        # T = TensorNetwork(\n",
    "        #     cores=[P, A, P.rename(\"m_*\", \"n_*\", inplace=False).rename(\"r_*\", \"t_*\", inplace=False)],\n",
    "        #     names=['P^T','A','P']\n",
    "        # ).contract(indices=get_idx2(j))\n",
    "        # U = TensorNetwork(cores=[P, b], names=['P','b']).contract(indices=get_idx(j))\n",
    "\n",
    "        # V = np.linalg.tensorsolve(T.view(np.ndarray), U.view(np.ndarray))\n",
    "        # V = TensorCore(V, indices=get_idx(j))\n",
    "\n",
    "        V = TensorNetwork(cores=[P, b], names=['P','b']).contract(indices=get_idx(j))\n",
    "        # print(V)\n",
    "        return V\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Left half sweep\n",
    "        for j in range(tt.order-1):\n",
    "            # Micro optimization\n",
    "            V = micro_optimization(tt, j)\n",
    "\n",
    "            core_curr = tt.cores[f\"core_{j}\"]\n",
    "            core_next = tt.cores[f\"core_{j+1}\"]\n",
    "\n",
    "            L = left_unfold(V).view(np.ndarray)\n",
    "            R = right_unfold(core_next).view(np.ndarray)\n",
    "\n",
    "            Q, S = np.linalg.qr(L)\n",
    "            W = S @ R\n",
    "\n",
    "            tt.cores[f\"core_{j}\"] = TensorCore.like(Q, core_curr)\n",
    "            tt.cores[f\"core_{j+1}\"] = TensorCore.like(W, core_next)\n",
    "\n",
    "        # Right half sweep\n",
    "        for j in range(tt.order-1, 0, -1):\n",
    "            # Micro optimization\n",
    "            V = micro_optimization(tt, j)\n",
    "\n",
    "            core_prev = tt.cores[f\"core_{j-1}\"]\n",
    "            core_curr = tt.cores[f\"core_{j}\"]\n",
    "\n",
    "            L = left_unfold(core_prev).view(np.ndarray)\n",
    "            R = right_unfold(V).view(np.ndarray)\n",
    "\n",
    "            Q, S = np.linalg.qr(R.T)\n",
    "            W = L @ S.T\n",
    "\n",
    "            tt.cores[f\"core_{j-1}\"] = TensorCore.like(W, core_prev)\n",
    "            tt.cores[f\"core_{j}\"] = TensorCore.like(Q.T, core_curr)\n",
    "\n",
    "    return tt\n",
    "\n",
    "\n",
    "# b = TensorTrain([4, 4, 4, 4, 4], [1, 3, 3, 3, 3, 1])\n",
    "b = TensorTrain([10, 10, 10], [1, 4, 4, 1])\n",
    "b.randomize()\n",
    "b.rename('r_*', 't_*')\n",
    "print(b)\n",
    "b.orthonormalize(mode=\"right\")\n",
    "\n",
    "b = TensorTrain.from_tensor(np.arange(10*10*10).reshape(10, 10, 10), ranks=[1, 8, 8, 1])\n",
    "b.rename('r_*', 't_*')\n",
    "print(b)\n",
    "\n",
    "\n",
    "a = np.random.rand(3, 4, 5, 3, 4, 5)\n",
    "#.reshape(4, 4, 4, 4, 4, 4)\n",
    "A = TensorCore(a, ['m_1', 'm_2', 'm_3', 'n_1', 'n_2', 'n_3'])\n",
    "# print(b, A)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "x = ALS(A, b, n_iter=100)\n",
    "print(f\"Elapsed time: {(time.time() - start_time):.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_ALS(X, b, n_iter=10, ranks=None):\n",
    "    shape = tuple(X.shape[1] for _ in range(X.shape[0]))\n",
    "    tt = TensorTrain(shape, ranks)\n",
    "    tt.randomize()\n",
    "    tt.orthonormalize(mode=\"right\", start=1)\n",
    "\n",
    "    def get_idx(j):\n",
    "        if j == 0: indices = (A[j].indices[0], *tt[j].indices[1:])\n",
    "        elif j == tt.order-1: indices = (*tt[j].indices[:-1], A[j].indices[2])\n",
    "        else: indices = tt[j].indices\n",
    "        return indices\n",
    "\n",
    "    def micro_optimization(tt, j):\n",
    "        P = retraction_operator(tt, j)\n",
    "        # V = TensorNetwork(cores=[P, b], names=['P','b']).contract()#indices=get_idx(j))\n",
    "        # print(V)\n",
    "        print(P)\n",
    "        for core in P.cores:\n",
    "            core *= b\n",
    "        return P.contract()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Left half sweep\n",
    "        for j in range(tt.order-1):\n",
    "            # Micro optimization\n",
    "            V = micro_optimization(tt, j)\n",
    "            print(V)\n",
    "\n",
    "            core_curr = tt.cores[f\"core_{j}\"]\n",
    "            core_next = tt.cores[f\"core_{j+1}\"]\n",
    "\n",
    "            L = left_unfold(V).view(np.ndarray)\n",
    "            R = right_unfold(core_next).view(np.ndarray)\n",
    "\n",
    "            Q, S = np.linalg.qr(L)\n",
    "            W = S @ R\n",
    "\n",
    "            tt.cores[f\"core_{j}\"] = TensorCore.like(Q, core_curr)\n",
    "            tt.cores[f\"core_{j+1}\"] = TensorCore.like(W, core_next)\n",
    "\n",
    "        # Right half sweep\n",
    "        for j in range(tt.order-1, 0, -1):\n",
    "            # Micro optimization\n",
    "            V = micro_optimization(tt, j)\n",
    "\n",
    "            core_prev = tt.cores[f\"core_{j-1}\"]\n",
    "            core_curr = tt.cores[f\"core_{j}\"]\n",
    "\n",
    "            L = left_unfold(core_prev).view(np.ndarray)\n",
    "            R = right_unfold(V).view(np.ndarray)\n",
    "\n",
    "            Q, S = np.linalg.qr(R.T)\n",
    "            W = L @ S.T\n",
    "\n",
    "            tt.cores[f\"core_{j-1}\"] = TensorCore.like(W, core_prev)\n",
    "            tt.cores[f\"core_{j}\"] = TensorCore.like(Q.T, core_curr)\n",
    "\n",
    "    return tt\n",
    "\n",
    "from bsde_solver.utils import flatten\n",
    "\n",
    "b = 12\n",
    "# Create a tensor of shape (4, 4, 4) from x with each axis with polynomial degree 1, x, x^2, x^3\n",
    "d = 4\n",
    "x = np.array([-1, -1, 0.5])\n",
    "X = np.array([x**i for i in range(d)]).T\n",
    "n = X.shape[0]\n",
    "\n",
    "V = scalar_ALS(X, b, n_iter=100, ranks=[1, 3, 3, 1])\n",
    "# Create tensor dot product of x (4, 4, 4)\n",
    "# print(X)\n",
    "# result = contract(*flatten([[X[i], ('a_'+str(i), )] for i in range(n)]))\n",
    "# X.shape, result.shape, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x.contract()\n",
    "bb = b.contract()\n",
    "print(\"Reconstruction error:\", np.linalg.norm(xx - bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.contract(indices=['m_1', 'm_2', 'm_3'])\n",
    "y = np.linalg.tensorsolve(a, c.view(np.ndarray))#, axes=([3, 4, 5], [0, 1, 2]))\n",
    "print(c.view(np.ndarray))\n",
    "print(a.shape, c.view(np.ndarray).shape)\n",
    "print(np.tensordot(a, y, axes=([3, 4, 5], [0, 1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.contract(indices=['m_1', 'm_2', 'm_3']).view(np.ndarray)\n",
    "\n",
    "print(np.tensordot(a, y, axes=([3, 4, 5], [0, 1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x.contract()\n",
    "bb = b.contract()\n",
    "print(\"Reconstruction error:\", np.linalg.norm(xx - bb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(10*10*10*10*10).reshape(10, 10, 10, 10, 10)\n",
    "Att = TensorTrain.from_tensor(A, [1, 2, 2, 2, 2, 1])\n",
    "\n",
    "print(\"Decomposition error:\", np.linalg.norm(A - Att.contract().squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.eye(4*4).reshape(4, 4, 4, 4)\n",
    "I = TensorTrain.from_tensor(Id, [1, 2, 2, 2, 1])\n",
    "\n",
    "print(\"Identity error:\", np.linalg.norm(Id - I.contract().squeeze()))\n",
    "\n",
    "\n",
    "id = TensorNetwork([TensorCore(Id, ['i', 'j', 'k', 'l'])])\n",
    "U = TensorNetwork([TensorCore(np.random.randn(4, 4), ['i', 'j'])])\n",
    "\n",
    "I.rename(\"m_1\", \"i\")\n",
    "I.rename(\"m_2\", \"j\")\n",
    "I.rename(\"m_3\", \"k\")\n",
    "I.rename(\"m_4\", \"l\")\n",
    "\n",
    "print(I, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
